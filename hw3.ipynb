{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bridal-league",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import roc_auc_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polar-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nasty-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "established-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opponent-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "streaming-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(y_true, y_pred, b=1):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    fscore = (1 + b ** 2) * (precision * recall) / (b ** 2 * precision + recall)\n",
    "    r_a_score = roc_auc_score(y_true, y_pred)\n",
    "    np.nan_to_num(fscore, copy=False)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    return thresholds[ix], fscore[ix], precision[ix], recall[ix], r_a_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-elimination",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerical-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indoor-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
    "                                                    df['cardio'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-boundary",
   "metadata": {},
   "source": [
    "К полям:\n",
    "- gender, cholesterol применим OHE-кодирование\n",
    "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
    "- gluc, smoke, alco, active - оставим пока как есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gentle-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-spectacular",
   "metadata": {},
   "source": [
    "Теперь объединим все наши трансформеры с помощью FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aging-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-significance",
   "metadata": {},
   "source": [
    "Добавим классификатор и запустим кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "available-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [LogisticRegression, \n",
    "              RandomForestClassifier, \n",
    "              GradientBoostingClassifier, \n",
    "              LGBMClassifier]\n",
    "classifier_list = [make_pipeline(feats, model(random_state = 42)) for model in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cleared-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for \u001b[1mlogisticregression\u001b[0m CV score is 0.787 ± 0.008\n",
      "for \u001b[1mrandomforestclassifier\u001b[0m CV score is 0.773 ± 0.006\n",
      "for \u001b[1mgradientboostingclassifier\u001b[0m CV score is 0.803 ± 0.008\n",
      "for \u001b[1mlgbmclassifier\u001b[0m CV score is 0.802 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "for pipe in classifier_list:\n",
    "    cv_scores = cross_val_score(pipe, X_train, y_train, cv=15, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print(f'for \\033[1m{pipe.steps[1][0]}\\033[0m CV score is {cv_score:.3f} \\u00b1 {cv_score_std:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "according-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "metrics = []\n",
    "for pipe in classifier_list:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict_proba(X_test)[:, 1]\n",
    "    names.append(pipe.steps[1][0])\n",
    "    thr, f1, pr, rec, roc = f_score(y_test.values, y_pred, b=1)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test.values, y_pred > thr).ravel()\n",
    "    metrics.append([thr, f1, pr, rec, roc, tp, tn, fp, fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "straight-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(metrics, \n",
    "                         index=names, \n",
    "                         columns=['Threshhold', 'F-score', 'Precision', 'Recall', 'ROC-AUC', 'TP', 'TN', 'FP', 'FN'])\n",
    "result_df['FPR'] = result_df['FP'] / (result_df['FP'] + result_df['TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "european-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshhold</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logisticregression</th>\n",
       "      <td>0.386937</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.837558</td>\n",
       "      <td>0.784035</td>\n",
       "      <td>7269</td>\n",
       "      <td>4861</td>\n",
       "      <td>3959</td>\n",
       "      <td>1411</td>\n",
       "      <td>0.448866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.718863</td>\n",
       "      <td>0.642669</td>\n",
       "      <td>0.815553</td>\n",
       "      <td>0.771037</td>\n",
       "      <td>7017</td>\n",
       "      <td>4991</td>\n",
       "      <td>3829</td>\n",
       "      <td>1663</td>\n",
       "      <td>0.434127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradientboostingclassifier</th>\n",
       "      <td>0.394947</td>\n",
       "      <td>0.740248</td>\n",
       "      <td>0.697848</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>6840</td>\n",
       "      <td>5858</td>\n",
       "      <td>2962</td>\n",
       "      <td>1840</td>\n",
       "      <td>0.335828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbmclassifier</th>\n",
       "      <td>0.344797</td>\n",
       "      <td>0.739561</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.839631</td>\n",
       "      <td>0.801689</td>\n",
       "      <td>7287</td>\n",
       "      <td>5079</td>\n",
       "      <td>3741</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.424150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Threshhold   F-score  Precision    Recall  \\\n",
       "logisticregression            0.386937  0.730323   0.647431  0.837558   \n",
       "randomforestclassifier        0.350000  0.718863   0.642669  0.815553   \n",
       "gradientboostingclassifier    0.394947  0.740248   0.697848  0.788134   \n",
       "lgbmclassifier                0.344797  0.739561   0.660803  0.839631   \n",
       "\n",
       "                             ROC-AUC    TP    TN    FP    FN       FPR  \n",
       "logisticregression          0.784035  7269  4861  3959  1411  0.448866  \n",
       "randomforestclassifier      0.771037  7017  4991  3829  1663  0.434127  \n",
       "gradientboostingclassifier  0.802615  6840  5858  2962  1840  0.335828  \n",
       "lgbmclassifier              0.801689  7287  5079  3741  1393  0.424150  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-sending",
   "metadata": {},
   "source": [
    "При b = 1(То есть в случае, когда для нас равно важны и precision, и recall)  \n",
    "\n",
    "Можно сделать вывод, что в нашем случае лучший результат(при условии базовых настроек моделей) показывает модель GradientBoostingClassifier из паката sklearn. FPR удалось снизить на 11% по отношению к рассматриваемой на занятии логистической регрессии. Кроме того, несмотря на в целом меньшее количество TP, значение precision также выше.  \n",
    "\n",
    "Далее нужно уже смотреть, что для нас важнее: охватить всех возможных больных или меньшее их количество, но с большей точностью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-transsexual",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-patent",
   "metadata": {},
   "source": [
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-shuttle",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-punishment",
   "metadata": {},
   "source": [
    "Осями на графике ROC являются значения TPR/FPR  \n",
    "На PR - precision и recall соответственно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-transport",
   "metadata": {},
   "source": [
    "$$ TPR = recall = \\frac{TP}{TP+FN} $$  \n",
    "\n",
    "$$ FPR = \\frac{FP}{FP+TN} $$  \n",
    "\n",
    "$$ precision = \\frac{TP}{TP+FP} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-southwest",
   "metadata": {},
   "source": [
    "Очевидно, что оси TPR и recall одинаковы, поэтому разницу нужно искать между FPR и precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-duncan",
   "metadata": {},
   "source": [
    "Можно провести эксперимент и посчитать соответствующие метрики для каждой из моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intensive-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество наблюдений\n",
    "N = 100000\n",
    "\n",
    "# Модель 1\n",
    "TP1 = 90\n",
    "FP1 = 10\n",
    "FN1 = 10\n",
    "TN1 = 99890\n",
    "\n",
    "# Модель 2\n",
    "TP2 = 90\n",
    "FP2 = 910\n",
    "FN2 = 10\n",
    "TN2 = 98990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "liberal-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = lambda tp, fp: tp / (tp + fp)\n",
    "fpr = lambda fp, tn: fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "periodic-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision M1: 0.9\n",
      "precision M2: 0.09\n"
     ]
    }
   ],
   "source": [
    "print(f'precision M1: {pr(TP1, FP1)}\\nprecision M2: {pr(TP2, FP2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "featured-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR M1: 0.00010\n",
      "FPR M2: 0.00911\n"
     ]
    }
   ],
   "source": [
    "print(f'FPR M1: {fpr(FP1, TN1):.5f}\\nFPR M2: {fpr(FP2, TN2):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-christmas",
   "metadata": {},
   "source": [
    "Очевидно, что значение FPR меняется от модели к модели незначительно, а вот precision отличается серьезно, что неудивительно, так как в нем учитывается количество ложно-положительных результатов. \n",
    "\n",
    "Можно сделать вывод, что для дисбалансных выборок PR-AUC метрика подходит лучше"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
